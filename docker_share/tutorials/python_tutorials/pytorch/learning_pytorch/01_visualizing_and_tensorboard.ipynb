{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Models, Data and training with Tensorboard\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Link](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)\n",
    "* [CIFAR-10 tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the CIFAR Tutorials\n",
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('../data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST('../data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TensorBoard setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 15:22:58.968947: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-28 15:22:59.041061: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-12-28 15:22:59.407765: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda11.7/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-28 15:22:59.407792: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda11.7/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-12-28 15:22:59.407794: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('../runs/fashion_mnist_experiment_2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Writing to TensorBoard\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inspect the model using TensorBoard\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Adding a \"Projector\" to TensorBoard\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the lower dimensional representation of higher dimensional data via the `add_embedding` method\n",
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target incides\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                        metadata=class_labels,\n",
    "                        label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tracking model training with TensorBoard\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained network and a list of images\n",
    "    '''\n",
    "\n",
    "    output = net(images)\n",
    "    # convert output probabilites to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images and labels from a batch, \n",
    "    that shows the network's top prediction along with it's probability, alongside the actual label,\n",
    "    coloring this information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                color=(\"green\" if preds[idx]==labels[idx].item() else \"red\")\n",
    "        )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1): # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999: # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('trainig_loss',\n",
    "                                running_loss / 1000,\n",
    "                                epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                                plot_classes_preds(net, inputs, labels),\n",
    "                                global_step=epoch * len(trainloader) + i)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Assessing trained models with TensorBoard\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (default, Nov  6 2019, 21:49:08) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1575894b3c56cb0000c31f06c89affaaca1d84533f8b8421570eed65a182f1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
